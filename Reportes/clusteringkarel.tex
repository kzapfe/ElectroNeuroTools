\documentclass{article}


\usepackage{graphicx}
\usepackage{subcaption}


\author{K. Zapfe}
\title{Spatiotemporal clusters in the CSD-CM representation}



\begin{document}

\maketitle


As an extension to the trajectory concept in the CSD-CM we
shall propose another,  more general, concept: spatial-temporal
clustering of the CM.
This extends the notion of trajectory to more general grouping of the
CM data.

In view of the need of classifying the CM by anatomical location,
the need of an automatic, unsupervised classification of the various CM
over the underlying physiological structure was seen.  The CM data
consists of 4 continuous numerical dimensions and a binary categorical
one. These are the 2 dimensions of of spatial location, which are constrained
to the dimensions of the MEA, the temporal variable (which can be
considered discrete if we use sampling frames as time unit), and the intensity of the CM.
The sign of the last one can be considered a separate categorical variable which
has the values ``Sink'' or negative, and ``Source'' or positive. 
Our problem was then to use the numerical variables to group the CM data in
a way that could sheed some light over the anatomical structure that
generates it. In the figure \ref{puntostodos} we present the CM data
in the MEA coordinates obtained from an experiment with facilitated activity
during a burst of spikes ( around 285 ms of recording ). A visual inspection
seems to suggest a clustering of the points in layers and segments over and near the
Cornu Ammonis Structure, with fewer points over other structures. Most interesting
is the three layered clustering that seems to be around CA3 and the two layered
structure in CA1. 

\begin{figure}
\centering
\begin{subfigure}{0.40\textwidth}
\includegraphics[width=\textwidth]{puntoscmfacneg.png}
\caption{Sinks}
\end{subfigure}
\begin{subfigure}{0.40\textwidth}
\includegraphics[width=\textwidth]{puntoscmfacpos.png}
\caption{Sources}
\end{subfigure}

\caption{The distribution of the CM of 285ms of data of facilitated activity
during a burst. We have of the order of 9000 points in each
set. Visual inspection seems to reveal a multilayered structure in the
CA3 and CA1 region, with more ambigous clustering in the putative
CA2 location.}\label{puntostodos}

\end{figure}

In the figure \ref{puntosconcolor} we also colorize the dots by temporal emergence.
This also reveals that the layering has also a recurrent order of appearance. Intensity
layering was also explored, but heuristic reasons based on previous trajectory
analysis put doubts on the validity of this classification. Namely, we expect
that the generalization of trajectories to also have a rising and fading behavior,
and thus the intensity should not be used to separate different cluster, but to
find regular activity inside each cluster. It could be argued that intensity also
classifies multi-unitary activity by type and number of putative units, but then,
this classification would require using intervals of intensity instead of mere
points and would complicate the analysis considerably.


\begin{figure}
\centering
\begin{subfigure}{0.40\textwidth}
\includegraphics[width=\textwidth]{puntoscmfacnegtcolor.png}
\caption{Sinks}
\end{subfigure}
\begin{subfigure}{0.40\textwidth}
\includegraphics[width=\textwidth]{puntoscmfacpostcolor.png}
\caption{Sources}
\end{subfigure}

\caption{Same data as in fig. \ref{puntostodos} but colorized using
the temporal appearence. The colorbar is in miliseconds. We can observe
that there is near simultaneus activation of the ``Sources Layers'' in CA3,
between other visual groupings. 
}\label{puntosconcolor}

\end{figure}


We decided to  use only the spatiotemporal variables for classification. 
The temporal variable has different units, so a prudent normalization is due
in order to not to give to it a preponderant or negligible weight in relation to the
spatial ones. In absence of any other information, the sensible thing to do is to
scale it so that its maximum span is of the same order of magnitude to the
spatial length of the data, namely 64 arbitrary units, which is the convenient unit
of measurement of the MEA ( 64 electrodes correspond to 2.27 mm).
With this normalization, the data of the CM exist in a 3 dimensional cube of 64 a.u.
of length on each side. We can then proceed to cluster the data according to
certain criteria.


Clustering algorithms vary not only in implementation, but in design criteria.
Thus they produce different results. We had to test a few of them. Our choice at the
end was the so called DBSCAN (Density Based Spatial Clustering of Applications with Noise).
This algorithm is conceptually clean and can produce heterogeneous clusters, in contrast
to others such as HDC ( Hierarchical Data clustering). The DBSCAN clustering depends
on two parameters: a radio of neighborhood and a minimal number of neighbors. Each
point that is deemed to be part of a certain cluster has to have that number of neighbors
that are also part of the same set inside an sphere of the chosen radius. These
parameters can be chosen on physiological grounds although we can device a more
abstract way of optimizing them. An example of the results of this
algorythm is shown on fig. \ref{puntoscluster}.
A strict choice of parameters (small radius and many neighbors) produces
very dense clusters and a lot of unasigned points. A laxer choice (a big radius
with one to three neighboors) produces few clusters, with sparcely populated
areas,  and fewer unasigned points. A quick testing of the algorythm 
shows that we have to explore the validity of clusters in the range of
$r \in [0.75, 2 ]$ ( electrode lengths) and $ n \in \lbrace 2,3,4,5 \rbrace$.


\begin{figure}[h]
\centering
\begin{subfigure}{0.40\textwidth}
\includegraphics[width=\textwidth]{dbscannegejem01.png}
\caption{Sinks}
\end{subfigure}
\begin{subfigure}{0.40\textwidth}
\includegraphics[width=\textwidth]{dbscanposejem01.png}
\caption{Sources}
\end{subfigure}

\caption{Same data as in previous figures, but the colorization is
  from a realization of DBSCAN clustering. The parameters used were
  $r=1.75$ a.u. for the neighborhood radius and 3 neighbors for each point.
  Those parameters give around 300 clusters, many of them with less than
  10 points. A good choice of parameters requires balancing
  the number of clusters and the number of unasigned points. 
}\label{puntoscluster}


\end{figure}


We decided to use a certain ``aesthetic'' criterium for choosing the optimal parameters
for the DBSCAN algorythm.  It is its accordance with Zipf's Law.  This could post out
the accordance with the allometric inverse algebraic laws that are observed in
anatomical studies, but it is, in the end, a somewhat arbitrary criterium.
Nevertheless, a good
fit with Zipfs Law could be an indictor of a natural clustering of data points.
A problem that appeard using this criterium is that it is such a pervarsive
behaviour of ranked data
that it gives a good fit to allmost any set of reazonable parameters
that one encounters. So we had to come up with criteria for what these ``reasonable
parameters'' may be.  We settled that we shouldn't have to many unasigned points, and
that no cluster should be too big, or that there were to many clusters. In the
table \ref{tablarquad} we show the fitting results for some values of
$r$ and $n$. The model that was fitted did not specify the exponent, it
is remarkable how the various models gave values for this parameter so close
to the ideal $-1$. 


\begin{figure}
  \centering
  \includegraphics[width=0.8\textwidth]{zipfexample.png}
  \caption{An instance of Zipf's Law, with DBSCAN parameters
    $r=1.5$ a.u. and $n=4$. The agreement with Zipf's
    gives an exponent of $-1.007$ against the ideal $-1$ and
    an $R^2$ of $0.986$.}
\end{figure}

\begin{center}
\begin{tabular}{|r|r|r|r|r|r|}
 r &  n  & $R^2$ & u & m & ng  \\ \hline
  1 &  2 &  0.978 & 606 & 606 & 1285 \\
  1 &  3 &  0.984 & 1346 & 1346 & 915 \\
  1 &  4 &  0.974 & 2300 & 2300 & 658 \\
  1 &  5 &  0.951 & 3193 & 3193 & 493 \\
  1 &  6 &  0.918 & 4023 & 4023 & 375 \\
  1.5 &  2 &  0.987 & 276 & 1007 & 691 \\
  1.5 &  3 &  0.987 & 660 & 1007 & 499 \\
  1.5 &  4 &  0.985 & 1060 & 1060 & 391 \\
  1.5 &  5 &  0.986 & 1523 & 1523 & 315 \\
  1.5 &  6 &  0.99 & 2040 & 2040 & 258 \\
  2 &  2 &  0.95 & 156 & 5355 & 343 \\
  2 &  3 &  0.928 & 382 & 5355 & 230 \\
  2 &  4 &  0.912 & 566 & 5349 & 174 \\
  2 &  5 &  0.906 & 777 & 5308 & 132 \\
  2 &  6 &  0.915 & 976 & 3734 & 112 \\
  2.5 &  2 &  0.911 & 113 & 6144 & 225 \\
  2.5 &  3 &  0.875 & 243 & 6144 & 160 \\
  2.5 &  4 &  0.849 & 349 & 6142 & 127 \\
  2.5 &  5 &  0.828 & 475 & 6127 & 100 \\
  2.5 &  6 &  0.849 & 602 & 6008 & 81 \\
  3 &  2 &  0.909 & 89 & 7408 & 163 \\
  3 &  3 &  0.874 & 187 & 7408 & 114 \\
  3 &  4 &  0.847 & 267 & 7404 & 89 \\
  3 &  5 &  0.829 & 343 & 7402 & 71 \\
  3 &  6 &  0.817 & 418 & 7400 & 58 
\end{tabular}
\caption{Table of $R^2$ values fitting Zipf's Law to the clustering
  rank and size for various parameters. Here $r$ is the neighborhood
  radius, $n$ the number of required neighboors including itself,
  $R^2$ is the coefficient of determination, $u$ is the number of
  unasigned points, $m$ the size in points of the largest
  cluster, and $ng$ the number of clusters. }
\label{tablarquad}
\end{center}

\end{document}

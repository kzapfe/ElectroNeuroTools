\documentclass[utf8]{frontiersSCNS} 




%\setcitestyle{square} % for Physics and Applied Mathematics and Statistics articles
\usepackage{url,hyperref,lineno,microtype,subcaption}
\usepackage[onehalfspacing]{setspace}

\linenumbers


\usepackage{siunitx}% para unidades chidas como micrometros.

\usepackage{caption}
\usepackage{subcaption}

% \doublespacing
% \linenumbers

\DeclareMathOperator{\arcsinh}{arcsinh}
\newcommand{\mum}[1]{\SI{#1}{\micro\metre}}
\newcommand{\muV}[1]{\SI{#1}{\micro\volt}}
\newcommand{\rd}{\mathrm{d}}

\newenvironment{intension}{\fontfamily{phv}\selectfont}{\par}



\def\keyFont{\fontsize{8}{11}\helveticabold }
\def\firstAuthorLast{W.P.K. Zapfe {et~al.}} %use et al only if is more than 1 author
\def\Authors{Wilhelm Pablo Karel Zapfe\,$^{1,*}$, Franco Ortiz\,$^{2}$ and Rafael Gutierrez\,$^{1}$}
%
\def\Address{$^{1}$Laboratory 19, CINVESTAV, Pharmacobiology Department , Mexico City , Mexico \\
$^{2}$Laboratory X, Institute X, Department X, Organization X, City X , State XX (only USA, Canada and Australia), Country X  }
\def\corrAuthor{W.P.K. Zapfe}
\def\corrEmail{kzapfe@cinvestav.mx}





\begin{document}
\onecolumn
\firstpage{1}


\title[CSD+CM]{Disjoint components and trayectory detection in CSD representation
for electrophysiological recordings}


\author[\firstAuthorLast ]{\Authors} %This field will be automatically populated
\address{} %This field will be automatically populated
\correspondance{} %This field will be automatically populated

\extraAuth{}% If there are more than 1 corresponding author, comment this line and uncomment the next one.

\maketitle


\begin{abstract}


\section{}
CSD representation of the extracellular electrophysiological activity of neuronal tissue lends itself
to an analysis of the propagation of activity. The CSD sepparates ionic urrents into sinks and sources on the extracelluar medium.
This differentation provides the means to separate disjoint loci of activity
and track them sepparatelly. The local effective connections would be the
main causes for this continous spread of activity. By obtaining the vectorial
average of an area regarded as sink or source, we obtain a putative center of
action. The succesive centers would reveal the inmediate nearby correlated
units that inherit or otherwise are triggered by this activity. For
structured tissue, this provides a clean means to infer effective excitatory
connections.

\tiny
 \keyFont{ \section{Keywords:} keyword, keyword, keyword, keyword, keyword, keyword, keyword, keyword} %All article types: you may provide up to 8 keywords; at least 5 are mandatory.
\end{abstract}



\section{Introduction}

Tracking the propagation of electrical activity in neural tissue poses challenging
problems. 
Micro Electrode Arrays (MEA) electrophysiological recordings usually consist of 
a series of traces, each one corresponding to a sampling
electrode on the tissue. Causality tests are made between the
signals in search for effective connections. 
As MEAs become denser,the data saturates itself
and the discovery of patterns becomes a difficult task.
Testing for combination of signals in large numbers
brings ``combinatorial explosion'' into
play. This makes the causality tests time consuming and
prone to produce false positives.
Novel information is obfuscated by the same high density acquisition that allows us to
discover it. Representing  the recorded data in ways which can unveil previously
invisible patterns is a necessity. Various techniques for separation of signals
are available now, most derived from the application of blind source
separation analysis, such as ICA.
In this paper we present a method that aims rather to integrate
the signals into functional components that
have physiological interpretation.
This is a technique for tracing out
``functional local connectivity'', which would bring independent information
that is complementary to Blind Source Separation.
Our  method would be applicable mostly to
activity in highly structured neural tissue. We shall exemplify it by
the data obtained from recordings of the rat's hippocampus,
taking advantage of its highly stratified  structure. 

Local field potential (LFP)
is generated by local multi-unitary activity.
A set of simultaneous and neighbouring traces
can be regarded as representant of the action
of those multi-unitary elements. 
Successive activation  of distinct neighboring elements on structured
tissue would trace a
``trajectory'' of the activity. A tracing of such trajectories would help to indicate
causal or correlated ``functional local connections'' over the tissue. Neighboring
neurons that fire in succession, integrated sub-threshold activity and ephaptic coupling
could all be encompassed as pathways for transmission of activity. Nevertheless,
how to define and acquire the putative paths is an open question.

In previous works some form of vector averaging has been proposed and shown to reveal some trajectories drawn by the activity. We shall call such methods Center of Mass Analyses (CMA).  The ``weights'' that have been chosen for obtaining the average have been selected on heuristic grounds. In the works of Chao \emph{et al.} \citep{Chao05, Chao07}, the density of spikes in a certain time interval was used, a sort of ``averaged density of action'', while Manjarrez \emph{et al.} \citep{Manjarrez07, Manjarrez09} used the positive half of the LFP recording as their weight. 
Here we advance on such methods by incorporating mathematically sound definitions and concepts which allow us to rigorously separate spatially distinct traces. Our weight is actually the natural density function provided by the data: the Current Source Density. This representation not only provides a mathematical rigorous  measure for the weights in the vector averaging process, but helps to separate the data into disjoint sets and disconnected components.
This allows us to track separate processes in the same region of interest
(r.o.i.) by following separately the distinct poles of action: influx and
efflux of charged ions, which normally correspond to two distinct phases of the
neuronal activity: depolarization and repolarization, respectively. 

The application of the method requires electro-physiological data acquired
through bi-dimensional MEAs, although the extension to three dimensional arrays
is straightforward.
The MEA should have dense enough spatial and temporal samplings,
so as to obtain good estimates of the CSD and their changes in time.

Our method permits us to map possible trajectories of activity inside structured neuronal tissue, without requiring ad hoc geometric constraints. As a prime example, non-convex structures which may show simultaneous activity in separate parts could show the robustness of our method. We have tested the method on slices of rat's hippocampus, focusing on the CA3 region. The slices are put over an array of 64 by 64 electrodes
(BioCAM 4096 by 3Brain \citep{BioCam}),
and data is recorded at sampling rates between 7 and 14 kHz. The richness of the
data is an exemplary use case for our method. A certain amount of down-scaling would be 
possible, but the array of electrodes should be at least 2 dimensional and
have an inter-electrode distance of the order of magnitude of a typical pyramidal cell's diameter
(around \mum{100} at most). (Una célula piramidal normalmente tiene un diametro de 30 micras. ¿Cuál valor quieres poner? ¿30 o 100?)




\section{Materials and Methods}

\subsection{Prepossessing}

After data acquisition, we preprocess the data to detect and discard unusable channels,
such as saturated or failing electrodes. The
number of failing electrodes varies from data set to data set,
as air bubbles can interrupt the contact between the tissue and the electrode or the electrode's signal may become saturated 
after electrical stimulation. (Aquí no quieres porner "any other cause" porque los referees pueden pensar que no llevas un buen control de tus experimentos) 
If the absolute value of the signal is above certain threshold (which must be
adjusted for evoked vs spontaneous activity, but
is of the order of \muV{1000}) or if the standard deviation is
larger than a two times the average r.m.s.  of the normal noise,
the channel is discarded.


\subsection{CSD for high density MEAS}

The first step is to obtain the CSD from the recorded LFP.
Any reliable method would work.
We have used two different
approaches. The first method is a  finite difference operator,
while the second is the kCSDA presented by
Potworowski \emph{et all} \citep{Potworowski2011},
which is an inverse problem approach.
Where both methods are usable, we prefer the former,
as it is faster and requires less assumptions.
We have used kCSDA where
the difference method is not applicable. The results are
independent of the method except for a multiplicative factor.
As there is still another unknown constant factor
(the resistivity of the medium), this is irrelevant.
Therefore, all of the CSD results are presented in arbitrary units.

Thanks to the density and scales of the BioCAM 4096,
the numerical finite difference method
produces an excellent approximation to the CSD,
if the number of failing channels is low or
they are outside the r.o.i.
In most examples the number of unusable channels is in the tens.
A  numerical Laplacian Operator which reduces the cross effect of
rectangular grids is the convolution of the data with the following
matrix \citep{Lindberg90}:

\begin{equation}
\nabla^2_{1/3}=2/3
\begin{pmatrix}
  0 & 1 & 0 \\
  1 & -4 & 1 \\
  0 & 1 & 0
\end{pmatrix}
+1/3
\begin{pmatrix}
  0.5 & 0 & 0.5 \\
  0 & -2 & 0 \\
  0.5 & 0 & 0.5
\end{pmatrix}  
\end{equation}
This sort of operators are very sensitive to abrupt changes in the values.
The noise of the data can be perceived in the spatial domain as rapidly varying edges. A Gaussian spatial smoothing
can be performed before or after the Laplacian operator to the data in order to reduce excessive borders. Our Gaussian blur filter has a $ \sigma$ value of \mum{63}, which corresponds to one and a half times the inter-electrode distance.
Intuitively this means that it smooths over each structures smaller than the soma of a typical pyramidal cell. 
This is  in accordance to our mean field approach, where we expect smooth differentiable fields over the scale of the neurons, but not in finer scales (for details see \citep{Bedard11}).

On previous works it has been argued that numerical difference operators sacrifice all data on the borders of the array. For electrode arrays of lesser density, this could posse a problem, but in our case we renounce to 253 out of 4095 channels (one is grounded), and those are outside the region of interest.
If very few electrodes fail, more sophisticated methods such as iCSDA \citep{Leski2011} and kCSDA \citep{Potworowski2011} prove little advantage.
In case that around 30 or more electrodes
fail, specially if they are on the region of interest or its borders,
the use of such methods
becomes necessary. The kCSDA method relies on the
assumption that a finite family of convenient functions can span, with acceptable accuracy, a very good approximation to the  CSD at each instant in time.
A general presentation is in the reference \citep{Potworowski2011},we shall recount only the basic implementation as we used it. The
method can be summarized into two steps:
\begin{enumerate}
\item One presents a family of model functions for the CSD and
obtains the LFP that such functions
would generate.
\item Then one proceeds to calculate
  the coefficients for the entire family by projecting the
  experimental data over this ideal LFP model function family.
\end{enumerate}

We shall borrow the notation in the original paper \citep{Potworowski2011}. Our model function for the CSD is a hard disk function, described by:
\begin{equation}
  \tilde{b}_j(x,y)=\begin{cases}
  1, \text{ for } (x-x_j)^2+(y-y_j)^2 \leq R^2 \\
  0 \text{ otherwise.} 
  \end{cases}
\end{equation}
The $R$ parameter is the effective radius of the charge density, which for our
calculations was taken as half the inter-electrode distance, that is $R=$\mum{21}.
Each pair $(x_j, y_j)$ is the center of one such model function, which we take as
the position of each  functioning electrode in an adequate coordinate system.
The LFP generated by this function would then be:
\begin{equation}
  \tilde{b}_j(x,y)=\frac{1}{2\pi\sigma}
  \iint \! \rd x \rd y \arcsinh \biggr(
  \frac{2 h } {\sqrt{(x-x_j)^2+(y-y_j)^2}}
  \biggl)
  \tilde{b}_j(x,y),
\end{equation}
  with $h$ being the effective height of the function support, in our case,
  the half width of the hippocampus slice ($h=$\mum{150}).

Then the kCSDA consist of projecting the experimental data (LFP), frame by frame,
over these model functions and obtaining the  coefficients that would spawn an idealized
LFP approximation. These coefficients are the same that would produce the
corresponding CSD. The first operator is the projection operator $K$ of the experimental
LFP (from now on $V(x,y)$) on the space of the idealized LFP (which we call $V^* (x,y)$).
\begin{equation}
  K_{jk}=\sum_{l=1}^{M}b_l(x_j,y_j)b_l(x_k,y_k).
\end{equation}
The sum is done over the set of $M$ electrodes that we want to use.
The other operator is the one that maps the space of $V^*(x,y)$ into the idealized
CSD functions, now called $C^*(x,y)$. 
\begin{equation}
  \tilde{K}_{jk}=\sum_{l=1}^Mb_l(x_j,y_j)\tilde{b}_l(x_k,y_k).
\end{equation}
Then $C^*(x,y)$ can be obtained on the region of interest by:
\begin{equation}
  C^*(x_j,y_j)=\sum_{k,l=1}^M \tilde{K}_{kj} K^{-1}_{ml} V(x_l,y_l)
\end{equation}
Notice how the method incorporates a denoising mechanism, so
no smoothing filters are needed.
The great advantage of this method is that is possible to obtain a reasonable
approximation to CSD even when the presence of unusable channels is near or inside
the region of interest. The difference method, on the other hand, affects all surrounding
channels to a failing channel, up to 8 of them, so it becomes unusable if enough
saturated electrodes are over the r.o.i.

It is important to mention that our data has noise up to 0.1 of the mean magnitude of the
signal, which means that regularization of the matrix $K$ is unavoidable (see section 4.1 in \citep{Potworowski2011} and references therein). We used a regularization parameter $\lambda=0.001 |e_{max}|$, where $e_{max}$ is the principal eigenvalue of $K$. 

The attainment of $K$ and $\tilde{K}$ turns out to be computer-costly for high density MEAs, but parallelization, specially on GPUs, solves this issue.


\subsection{CSD as weight density for vectors}


Center of Mass Analysis (CMA) has been used previously in order to track putative  ``trajectories'' of the activity or information across neural tissue or even the whole brain \citep{Chao05, Chao07, Manjarrez07, Manjarrez09}. In such works the chosen ``mass'' was an heuristic measure adequate for representing the coarse-grain picture of displacement of activity. These present the problem of justifying the choice made on practical grounds. For calculating a vectorial average, the adequate weight per vector is a density, a positive quantity that measures the concentration of something per space unit, so it is only adequate that we search for a natural density in the electro-physiological experiments. The Current Source Density fits the mathematical and interpretative requirements. We shall denote it in the following as $C$ (following \citep{Potworowski2011}).  This measure is usually presented in arbitrary units, which permits us to interpret it two-fold. One, directly from its definition, as the \emph{differential divergence} of the vectorial electric current density:
\begin{equation}
  C:=\nabla \cdot J
\end{equation}
Due to conservation of charges, this is the same as as the temporal variation of density of charge:
\begin{equation}
  C=-\frac{\partial \rho}{\partial t}
\end{equation}
Current Source Density as a mathematical density (a quasi-probability density function)  allows  to rigorously apply the concepts of vector averaging. This use has been overlooked. This might have occurred because  samplings at lesser spatial resolution did not permit estimations of this quantity with enough precision to make reliable spatial implications, even with the use of sophisticated CSD estimation methods. In our case, we want to use the density as a mathematician would: a function which assigns weights to points in the space of interest and permits us to carry linear operations over them.  The space here is the sampling points of the electrodes at a given instant in time, and the weight, the CSD, is amount of interchange of charged ions from the inside to the outside of cellular membranes, per unit space.  This is an indicator of activity in the neurons, therefore the CSD is also, indirectly, a \emph{``density of local activity''}. Having both
the mathematician and electro-physiologist interpretations present we can
perform the following analysis.

Apparently, CSD would not fit the requirements of non-negativity for its use as a mathematical density. This is not a problem.  CSD separates the measured activity into three distinct sets, namely, the set of all sources, the set of all sinks and the zero set. The separation is not quantitative but qualitative: even when the signs of electric charge are arbitrary, the distinction between them is not. Therefore, CSD represents on each of the two active sets (sinks and sources) exactly what we need, a unit of concentration of changing charges per unit of space (in this case, per area), and the sign can be ignored, as long as we perform the operations in each set separately. Also, the separation by the zero value set of the CSD is in contrast to the zero value of the LFP, where it has no precise meaning as it only represents a practical reference value. This is acknowledged in most of the literature, where only the scales of the LFP recording are shown, without reference to the sign of the values. In the CSD representation,  the so called zero set (all the points in our space which have a recorded CSD of zero)  has a precise meaning: it is an instantaneous lack of activity and the border between sinks and sources. This shall be exploited further in the section below.

Once the separation into sinks and sources has been made, we would have two densities, or more precisely, two different density functions defined over two separate sets. Trying to use this for obtaining vector averages would still be crude and inexact. If these sets spread out over large non-convex areas, the vector averages could lie outside the sets, having little or none physiological interpretation. Therefore we decided to introduce another concept from geometrical sets in order to reduce the analysis to local effects.


\subsection{CSD and Disconnected Components}

A first visual inspection of the CSD color map at a given instant in time shows that both sources and sinks appear in rather large and significant patches, with typical
cross lengths around \mum{150}. .
These appear to correspond to the expected poles of firing neurons in structured tissue \citep{Buzsaki2012} and inspired us to separate the sink and source  sets into their \emph{disconnected components}. This concept is used in mathematics to denote subsets of a given geometric set that do not touch each other  \citep{Halmos}. Their rough correspondence to poles of firing neurons is most useful in tracking the successive locus of the activity.

To clarify the concept and how we are using it, an example is necessary. In figure \ref{disconnectedsets} \textbf{A} we show geometrical sets enclosed by simple curves as color patches, where every color indicates a set. The set $A$ consists of a single connected component, that means that one can make  path between any two points in the set that consist entirely of points of the same set. In contrast, the set $B$ is made of two disconnected components, labeled $B1$ and $B2$. If one chooses a point in each of the components, one cannot draw a path joining them without leaving the set. But each one of those components is connected, meaning that if we choose the pair of points in one component, then again we can trace a path joining them in the set. So the set $B$ consists of two disconnected components, but each component can be regarded as a connected set on their own. Likewise the set $C$ is made of three disconnected components. In the subfigure \ref{disconnectedsets} \textbf{Aiii} we show the center of mass of the sets. The set $A$ is concave, so, it can have a center of mass outside the set. The
set $B$ has also a center of mass outside the set. It has two disconnected components that are approximately
equal and separated by a long distance (this is not an implication: a set can be disconnected and have
a CM inside the set). For the set $C$ our approach has been used: we treat every disconnected component of the
set as an independent entity and calculate the center of mass for each one. Notice that this doesn't preclude t
he possibility of having a concave subset with a CM that lies outside. But, as we shall see,
as the electrode resolution is finite, the possibility of having highly non compact shapes is unlikely, and they
tend to have a CM inside or near their borders. In the figure \ref{disconnectedsets}
\textbf{B} we show this with experimental
data (we are using evoked activity data, as explained in section \ref{sec:evocada}). In graph
\textbf{Bi} we
separate the CSD data into the sink and sources set. We take sinks as example. In the graph
\textbf{Bii}
we label each disjoint component, obtained by a single pass algorithm. There are 25 components, and
the bigger two are non convex. In the
subfigure \textbf{Biii}
we indicate the CM of only those components that are above certain threshold of
integrated intensity (the circle size  is proportional in area to such intensity, there are five CM to be
seen). Each CM gets listed as a probable step in a trajectory.



Theoretically, CSD would divide the set of measuring points into three subsets: the set of all sources, the set of all sinks, and the border between them.
It is impossible to define a precise zero value.
The measurements produce a function over the grid elements (the electrodes).
Noise between patches corresponding to a single set often makes bridges
between components, making identification of poles inexact.
In order to avoid this we create a ``thick neutral set'' of all the recording
points whose CSD values are inside an error interval around zero.
This separates more sharply the components of the set,
represents our ignorance of precise borders and helps
us to simplify the following analysis.

The ``thick neutral set'' would help us to separate the sinks and sources sets into
its disconnected components, which would correspond then to clear patches of
definite activity. If each one of these patches could be
interpreted as an active unit,
we may assign to it a ``center of activity'' in order to follow their displacements.
A Center of Mass for each instantaneous disconnected sink/source would provide us
a pragmatic measurement of an ``active locus''. We can then calculate at each time
frame the CM for each one of those components before tracking displacements of activity.

In each component, indexed $k$, at a given time $t$,, we have a number of points
(representing electrode centers)
with CSD of the same sign, indexed $j$. Then, the CM of the $k$-th
component would have the usual definition:
\begin{equation}\label{cmparadisj}
   \langle q(t) \rangle_k =\frac{\sum_j q_{j,k} (t) I_{j,k} (q_{j,k},t)}
           {\sum_j I(q_{j,k},t)},
\end{equation}
where $I(q_{j,k},t)$ is the CSD at point $q_{j,k}=(x_{j,k}, y_{j,k})$ at time $t$,
and the
sign of our ``density mass function'' eliminates itself graciously.
These disconnected components, while not rigorously convex,
are not largely spread over the space of the measurements.



\subsection{CM and trajectories}

We must not take out of sight the phenomena which is producing the CSD distribution:
neurons have a finite size, and the effect of their action a delimited extent.
Every patch that we can identify as a disconnected component of the Sources/Sink
sets indicates a joint active set of units. A center of mass for each disjoint
component would then indicate an average locus for this active group, a putative center of activity to which we can give a position, intensity and time. An instantaneous snapshot of such information would depict the centers of activity of an ordered structure of neurons and their relative intensities. But it is in the successive depiction of a series of such snapshots that this analysis can show interpretative power. The appearance , displacement, and disappearance of such centers could reveal very subtle details of the dynamics of neural activity. Very small, fast displacements of the Centers of mass, may be occur due to slight asynchronous action between neurons which belong to the same active group.
Larger displacements and longer intervals (more than two or so firing periods)
could indicate physiological connections between different groups or units.

The next step in our analysis is a procedure to systematically associate to each CM
at time $t$ a ``successor'' at time $t+\Delta t$, where $\Delta t$ is the sampling
time step. Let $q_1=(x_1, y_1)$ be the coordinates of the first point and $q_2=(x_2,y_2)$,
the corresponding coordinates of the second.
Remember that these coordinates can be now
rational numbers
respect to the grid of electrodes,
as CM are not restricted to be at the grid points.
The distance is:
\begin{equation}
d(q_1,q_2):=\sqrt{(x_1-x_2)^2+(y_1+y_2)^2}.
\end{equation}
The integrated intensity of a CM is simply the denominator in the
eq. \ref{cmparadisj},
that is, the total ``mass'' obtained by integrating the CSD in a specific component:
\begin{equation}
  I_k(t)=\sum_j I (q_{j,k}, t).
\end{equation}
We specify then a tolerance $\delta$. If a certain $t$ a CM is below $\delta$ distance from another at $t+\Delta t$, we consider the latter the successor in time of the former. By continuously applying such procedure, we can begin to trace trajectories of the CMs, as they appear, wander, and fade. 

When a specific trajectory cannot find a successor point that is above the
threshold intensity, we assume that it has ended, so we do not concatenate
points that are separated in time by more than $\Delta t$.
In order to concatenate different
trajectories more rigorous analysis of their origin and interpretation
should is due and is beyond the scope of this work.



 \subsection{The Procedure}
 
 In order to perform the analysis described here, we summarize the steps.
 \begin{enumerate}
 \item Acquire high density extracellular electro-physiological data. The data must be two
   dimensional
   in space. Distance between the recording sites must be of the order of the typical
   size of the neurons involved or less, and such sites must be on a dense enough grid to perform numerical difference operations over them.
   The sampling frequency should be enough to detect sub-threshold activity,
   of at least 3kHz. Also, the data should come from structured tissue.
   Unordered, highly homogeneous tissue, will not yield interpretable results. 
 \item Calculate the CSD from the data. Any method may be used,
   but computer expensive techniques are discouraged if the
   number of channels is above the thousands.
   Common sense and tests are guidelines here.
   We recommend simpler, difference based approaches wherever possible.
   If many electrodes fail near the r.o.i.,
   kCSD is a good alternative if performed using
   parallel CPU or GPU computing.
   If too many electrodes are failing over the r.o.i.,
   it is better to discard the data. 
 \item Separate the CSD data into three sets: sources, sinks, and neutral.
   Again, sensible criteria have to be defined.
   A rule of thumb would be to use the mean of the peaks of the noise  of the recording as the amplitude for the ``neutral'' range of values. 
\item Perform disconnected component analysis in the sources and sinks sets, frame by frame.
  A single pass algorithm here is  adequate \citep{Vincent91, Abubaker07}.
\item  Obtain the CM for each component, using eq. \ref{cmparadisj}. Discard
  all CM that are below some significant threshold value. A rule of thumb is one tenth of the average value for all CM,
  or those who are in the lesser decil. 
\item For each frame and its successor, and for each CM, perform a ``most probable successor'' detection. Here we must put numerical criteria according to the data available, i.e. how far away and how different in intensity should be allowed a CM to be at time $t+1$ to be considered successor in time of another at time $t$.
\item ``Connect the dots'', that is, apply successively the step above for each CM, until it stops having a successor or its intensity falls below the error criteria. Then plot the successive CMs as one trajectory.
\item Plot all the trajectories and sort visually those that may have physiological interpretation from those who may be artifacts of the method. This may need some form of expert validation.
 \end{enumerate}
 

 
\section{Results}

The necessity to create such analysis came originally from the study of
electro-physiological data obtained from the in vitro (poner "in vitro" en cursivas) rat's hippocampus, using
a very dense MEA, the BioCAM of 3Brain \citep{BioCam}. 
The highly layered CA structure of the hippocampus provides strong, discernible patterns of Sources and Sinks. Following the paths of activity using Center of Mass analysis directly from the data, though, proves unfruitful, due to the non-convex nature of the somatic layer. Using CSD and disconnected component tracking over the data provided the right conceptual framework to follow the displacement of active areas during highly active events, such as epileptic-like activity that was pharmacologically
or traumatically induced. The proposed analysis would not produce vector averages over different simultaneously active areas. On the contrary, it would separate them and track them independently. So the most violent epileptic burst provided us with the data necessary to prove the robustness of the method.
 



\subsection{Application to evoked activity in the rat's hippocampus}\label{sec:evocada}

Evoked activity by electrical stimulus yields simpler and cleaner patterns in the LFP
measurements. This facilitates the exemplification of our analysis, and gives us
a good starting case. It comes at a cost, nonetheless, as many of the electrodes
remain saturated after the stimulus and well beyond the measurement interval.
The data was obtained by stimulating  specific points on the dentate gyrus
(DG) in the slice of hippocampus with different voltage intensities. Details of the experiment
have been published elsewhere \citep{Franco2018}. We shall borrow some of
the experimental data for our purposes.



%The treatment of the data is shown in figure
%\ref{CSD_Evocada01}.  The subfigure A  shows a diagram of the hippocampus, with
%the somatic layers (CA and DG) as thick black lines and the stimulus point
%shown as a blue arrow. The $a,b,c,d,e$ dots are selected electrodes for
%showing LFP and CSD traces. Those are shown in the subfigure B. In subfigure
%C the same data is presented as a spatiotemporal color map that
%shows the expected poles of firing neurons transverse to the
%pyramidal stratum.  In the subfigure D we show the CSD for a series of time frames
%over the square delimited in the subfigure A. The idea for treating the different
%patches separately becomes evident here. The sources and sinks form patches
%with an apparent anterograde movement from CA3 to CA1.
%The patches change polarity
%as expected, with the somatic layer becoming a strong sink between 3 to 4 ms
%after the stimulus, and then, at the 6 ms, inverting its polarity in a way that suggest
%successive activation of groups that are represented as movement of the patch.



The LFP is averaged over three responses, produced by three successive
electrical stimuli in the same point at constant voltage. The
response of the cells is almost identical in each event, which
allows us to use averages as a denoising mechanism. After averaging
we perform kCSDA. In this case there are
many saturated electrodes and dCDSA is not viable.
In the figure \ref{lfpevocada} we show some frames of the post-stimulus
activity as a color map, along
with a diagram of the somatic layers and the
stimulus point. The saturated area is quite large, and covers
a large section of the DG structure. In this case we shall
restrict the CM track analysis to the respondent area in CA3.

In the figure \ref{trazselectevo} we show a sample of the LFP
raw traces and how they appear in the CSD representation. A diagram
over a frame of the LFP is shown delimiting the region of interest and
some selected electrodes. 

Once that we have the CSD representation, we select channels outside
the r.o.i. and use them to obtain the threshold for separating
the Sink and Sources sets. Then we proceed as stated in the previous section.

The figure \ref{lfpcsdcm}  compares the representation of the activity in
the LFP, CSD and CM spaces. The CSD
representation provides better spatial localization of active sites, and the
CM serves as better dynamical tracker. The figure illustrates
that point by choosing the time interval of response in CA3 after the stimulus.
CM representation permits us to track the activity with less
interference from the saturated region. The small, clearly localized centers of
mass separate clearly from the big patch over the saturated region.
In the figure \ref{lfpcsdcmsub} we repeat the procedure but focusing in
the r.o.i., which includes CA3 str. pyr. We take advantage of the
detailed frame to show the borders of the disconnected sets that
we have chosen for the CM analysis in the right column.


In the figure \ref{evotracks} we concatenate the successive centers of mass
for both sinks and sources and show how the anterograde reaction is
very well localized over the Pyramidal Stratum at a precise moment after
stimulus. This dataset provides us with a very clean example of the
trajectory analysis. The localized activity and coherent
action gives us trajectories that are in accordance with the expected
source and sink distribution, but adding the temporal dynamical displacement
to it. We have been very thorough with this example as it will help us
to understand the more complicated data that shall be presented in
the next examples. 

The evoked activity seems to yield much cleaner results, as we can now compare the trajectories of successive, very similar events. Our CSD and CM analysis can be used to detect consistent features in these experiments, such as the direction the waxing and waning of activity. Small deviations from the trajectory in successive experiments that are above the numerical error could indicate changes in response from
the underlying network. 





\subsection{Application to facilitated activity through injury}

A very small transversal cut of the enthorrinal cortex produces
a higher level of activity in the stratyum pyramidale. We call
this ``facilitated activity''. This activity shows bursts
that are epileptic-like (see fig. \ref{trazfaci}.
The CSD produces a very clean
image in CSD representation (fig. \ref{lfpcsdcmfaci}). 
This kind of trajectories form strata over the CA region,
showing a preference for CSD sites to be ordered by layers,
as can be seen on the figure \ref{facitracks}.
Careful examination of these figures show that trajectories
are either parallel or ortogonal to somatic strata, with small
deviations from this rule. This is notorious in the sink (blue)
trajectories, and should be interpreted accordingly.



%%%% *********** Vas aqui

\subsection{Application to epileptic-like activity in the hippocampus}


This is probably the most complicated data, 
numerically and qualitatively, which comes from a series of epileptic burst
that occurred after 15 minutes of application of 4AP to living slices of
hippocampus. Each burst occurs with activity spreading over many sites almost
simultaneously. This turned out to be a test of the applicability and
robustness of our method.
The necessity of having a good error value for the inactive set was more apparent here
than in the other cases. Also, the most striking features of the propagation of activity,
coded now as trajectories of the CM, could be seen here, as the epileptic burst covered the whole
CA structure. A sample of the raw data in $\muV{}$ can be seen in the figure \ref{lfpycsd4ap}. In the figure \ref{traz4ap} some exemplary traces
can be seen.
Five key moments in the epileptic burst have been selected, one just before the onset of the attack, the next one at the peak and one following it, and the last at the subsiding moments. The figure compares the Raw data
in $\muV{}$ in the first row, then the raw CSD representation in the second row, and
in the third raw a CSD after a Gaussian Blur Filter has been applied,
with a $\sigma$ value of $ \mum{42}$. After the Gaussian Blur acts a sort of
spatial denoising mechanism, the disjoint components are apparent to the eye.
In the figure \ref{csdfrontera} we separate the disjoint
components. Again, in the first row we have the CSD without the Gaussian Blur.
Even though well localized patches of activity are to be seen over the
stratum pyramidale, large parts of the activity remain hidden by the noise.
After the Gaussian Blur has been applied the joint sets of activity are evident. 

In the figure \ref{tray4ap} we show the epileptic burst on the trajectories representation.
Fine lines
connect the blue (sink) and red (source) dots, that indicate the trajectories
along various activation
sites around the whole CA structure, and part of the DG. Very small trajectories precede
the onset of the epileptiform attack in CA1. At around 60ms after the 4AP dose, a burst
of localized trajectories appear near CA2. By the 70ms mark, the activity has spread
retrogradely through most of the CA structure. Between the 80 and 90 ms marks,
DG shows knot-like trajectories. By 140ms the remaining activity is in the proximal
area of CA1.




\subsection{Counterexample: the stratial neuronal tissue}

 Larger scale recordings (macroscopic
structures) may gain something of this analysis, but we shall focus
our result to the neurons scale ( distances of the order of \mum{10}).

The stratial tissue is an example of where this analysis cannot be used.
The limitation of this technique is that it works  in
ordered, stratified neuronal tissue, and highly homogeneous tissue
without clear structures makes the distinction of both the CSD and
disconnected sets unfeasible.



\section{Discussion}

We have presented here a numerical tool that can help neurophysiologist in
discovering functional connections in structured tissue.
It is based on previous similar ideas, but the mathematical framework
which permits a rigorous application was lacking. Also, we have
shown that this ``current source density approach'' to the vector
averaging ideas permits sepparation of active sites and therefore,
and independent tracking of each inluencing action over
their surroundings.

In another paper 
we have shown an example with interpretation \citep{Franco2018}.
In this technical report we have shown in detail the process and ideas
that support it but without much physiological interpretation.
The main idea is to be able to track reliably and somewhat easily
the succession of active sites in the neuronal tissue. It may be that the best
examples are those that have epileptic bursts or some
sort of induced excess activity. In tissue that is highly homogeneous,
or unstructured, this technique is useless. Also, if the activity is
subtle, or shows very reduced local correlation, as opposed to long
range spatial correlations, the analysis may prove not very useful.
The sink and sources trajectories has to be made by the activation
of neighbouring units to make sense. The plausible explanation for these
active neighbours would be that they correspond to the same processing
circuitry, and thus, the trajectory would reveal its existence and,
possibly, some of the simplified pathways that it contains.
It is pertinent to remind that those trajectories are not
connections themselves. They are indicators of highly correlated
activity as measured from the outside of the cells. This correlation is
both temporal, spatial, and causal, so it is a good indicator
of possible physiological connection, but it doesn't say of what type it
is or if it is monosynaptic or polysinaptic.

We may point out some possible future uses for this analysis.
If somewhat less noisy electrodes are developed, and their density
increases by a factor of two or four, a very precise mapping of the
trajectories, in conjunction with an ICA, would reveal active
cells that form part of the same functional circuitry. Different
kinds of connections could be revealed by using some blocking
or stimulating drugs, and comparing trajectories in different conditions.

I would very much suggest a similar analysis done on
the visual cortex by exposition to visual imaginary
that has softly moving stimulus. (Esto no se entiende bien. Igual podrías borrarlo o explayarte más)

Three Dimensional MEAS are becoming also a reality.
In structured tissue, this kind
of analysis would be very revealing. If the electrodes
are dense enough, we may be able to trace the different units at
different strata stimulated by a single axon.



\section*{Figure captions}

\include{figurastmp}


\bibliographystyle{frontiersinSCNS_ENG_HUMS}
\bibliography{../Reportes/BiblioReportes01} 



\end{document}



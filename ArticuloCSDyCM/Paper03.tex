\documentclass{article}

\usepackage{amsmath}
\usepackage[utf8]{inputenc}
\usepackage[margin=1in]{geometry}
\usepackage{lscape}
\usepackage{mathptmx}
\usepackage[scaled=.90]{helvet}
\usepackage{courier}
%\usepackage{lipsum}% just to generate filler text
\usepackage{setspace}
\usepackage{graphicx}
\usepackage{longtable}

\begin{document}

\section{Introduction}

Spatialy tracking the activity of electrophysiological data in a clear, concise, and interpretable manner is a challenging problem. 


\section{CSD, CM and Disjoint Components}

\subsection{CSD as weight density for vectors}

One of the most obvious uses of the Current Source Density (CSD) in place of the Local Field Potentials (LFP) has been overlooked. This might have occurred because  samplings at lesser spatial resolution did not permit extending the implications of the concept of density. Density is \emph{quantifiable entity per unit of space}, or, in other words, concentration of something which is distributed in space. In this case, the ``something'' are the sources and sinks of electric current. Those can be interpreted as the interchange of charged ions from the inside to the outside of cellular membranes. This is an indicator of activity in the neurons, therefore the CSD is also, indirectly, a \emph{``density of local activity''}. Some of the advantages of this representation of the activity in place of the LFP have been stated many times (better spatial resolution, mostly). To the best of our knowledge, the conceptual advantages of using this density as such has never been done. A density is the adequate concept for calculating integrated measures, such as \emph{weights} of units or entities, \emph{averages} and others. We are particularly interested in its use for obtaining \emph{vector averages}, also known informally as Centers of Mass (CM).  


Center of Mass Analysis (CMA) has been used previously in order to track putative  ``trajectories'' of the activity or information across neural tissue or even the whole brain \cite{Chao05, Chao07, Manjarrez07, Manjarrez09}. In such works the chosen ``mass'' was an heuristic measure adecuate for representing the corse-grain picture of displacement of activity. These present the problem of justifing the choice made on practical grounds. For calculating a vectorial average, the adecuate wheight per vector is a density, a positive quantity that measures the amount of something per unit volume, so it is only adequate that we search for a natural density in the electrophysiological experiments, and the mos obvious one is the CSD which can be obtained through various methods from the LFP recordings if the spatial sampling is rich enough. 

Apparently, CSD would not fit the requirements of non-negativity for its use as a mathematical density. CSD sepparates the measured activity into three distinct sets, namely, the set of all sources, the set of all sinks and the zero set. The sepparation is not quantitative but qualitative: even when the signs of electric charge are arbitrary, the distintion between them is not. Therefore, CSD represents on each of the two sets (sinks and sources) exactly what we need, a unit of concentration per unit space, in this case, per area, and the sign can be ignored. The separation by the zero value set of the CSD is in contrast to LFP or EEG measurements, where the zero set has no precise meaning as it only represents a practical ground value. This is aknowledged in most of the literature, where only the scales of the LFP recording are shown, without reference to the sign of the values. Here the zero set has a precise meaning as instantaneous lack of activity and sepparation between sinks and sources. This shall be exploited when we explore a further refinement of the analysis.

Once the sepparation has been made, we would have two densities, or more preciselly, two different density functions defined over two sepparate sets. Trying to use this for obtaining vector averages would still be to crude. If these sets spread out over non-convex geometries, the vector averages could lie outside the sets, having little or none physiological interpretation. Therefore we decided to introduce another concept from geometricall set theory in order to make the analysis more local in character.



\subsection{CSD and Disjoint Components}


A first visual inspection of the CSD color map at a given instant in time shows that both sources and sinks appear in rather large and significant patches. These appear to correspond to the expected double and triple poles of firing neurons in structured tissue \cite{} and inspired us to separate the sink and source  sets into their \emph{disjoint components}. This concept is used in mathematics to denote subsets of a given geometric set that do not touch each other. Their rough correspondence to poles of firing neurons would be most useful in tracking the successive locus of the activity.


To clarify the concept and how we are we using it an example is in order. In figure \ref{ejemplodisjuntos} we show geometrical sets enclosed by simple curves as color patches, where every color indicates a Set. The set A consists of a single component, that means that one can make  path between any two points in the set that consist entirely of points of the same set. In contrast, the set B is made of two disjoint components, labeled B1 and B2. If one chooses a point in each of the components, one cannot draw a path joining them without leaving the set. But each one of those components is connected, meaning that if we choose the pair of points in one component, then again we can trace a path joining them in the set. So the set B consists of two disjoint components, but each component can be regarded as a connected set on their own. Likewise the set C is made of three disjoint components. 
 
Theoretically, CSD would divide the set of measuring points into three subsets: the set of all sources, the set of all sinks, and the border between them i.e, the set of all measuring points that have a CSD positive value, the set of those who have a negative CSD value, and the set of those points having exactly the zero value in CSD space.
Due to the finite precision of the measurement, the validity of the mean field approach, and the noise in the measurements, the sinks and sources sets can make contact with each other. Said measurements produce a function over a discrete point set, but we tend to think of them as continuous functions. Also, noise between patches corresponding to a single set could make a ``bridge'' between components, making identification of poles inexact. In order to avoid this we create a ``thick zero'' set of all the recording points whose CSD values are inside a small error interval around zero. This separates even more the components of the set, represents our ignorance of precise borders and helps us to simplify the following analysis.

The ``thick zero'' would help us to sepparate the sinks and sources sets into its disjoint components, which would correspond then to clear patches of definite activity. If each one of these patches could be interpreted as an active unit, we may asign to it a ``center of activity'' in order to follow their displacements. A Center of Mass for each nstantaneous disjoint sink/source would provide us a very sensitive measurement of ``active locus''. We can then calculate at each time frame the CM for each disjoint component before tracking displacements of activity.

At each disjoint component at a precise time $t$, indexed $k$, we have a number of points with CSD of the same sign, indexed $j$. Then, the CM of the $k$ component would have the usual definition:
\begin{equation}\label{cmparadisj}
   \langle q(t) \rangle_k =\frac{\sum_j q_{j,k} (t) I_{j,k} (q_{j,k},t)}
           {\sum_j I(q_{j,k},t)},
\end{equation}
where $I(q_{j,k},t)$ is the CSD at point $q_{j,k}=(x_{j,k}, y_{j,k})$ at time $t$. These disjoint components, while not rigorously convex, are less spread over the space of the measurements and tend to have their CM over the actual active points, or at the border of the active units.

\subsection{CM and trajectories}

We must not take out of sight the phenomena which is producing the CSD distribution: neurons have a finite size, and the effect of their action a delimited extent. Every patch that we can identify as a disjoint component of the Sources/Sink sets indicates a coherent, joint active group of units. A center of mass for each disjoint component would then indicate an average locus for this active group, a putative center of activity to which we can give a position, intensity and time. An instantaneous snapshot of such information would depict the centers of activity of an ordered structure of neurons and their relative intensities. But it is in the successive depiction of a series of such snapshots that this analysis can show power. The appearance , displacement, and disappearance of such centers could reveal very subtle details of the dynamics of neural activity. Very small, fast displacements of the Centers of mass, may be occur due to slight asynchronism between neurons which could belong to the same active group. Larger and  slower than a few firing periods displacements could indicate physiological connections between various groups.

The next step in our analysis would then a procedure to systematically associate to each CM at time $t$ a ``successor'' at time $t+\Delta t$, where $\Delta t$ is the sampling time step. We have used a pseudo-distance function which takes into account the geometrical distance from the putativa succesors for a CM, and also the intensity. For two CM inside our measurement space we define our pseudo-distance as follows. Let $q_1=(x_1, y_1)$ be the coordinates of the first point and $q_2=(x_2,y_2)$, the corresponding coordinates of the second, and let $I_1, I_2$ be their corresponding integrated intensities. Then the ``distance'' that separates them shall be 
\begin{equation}\label{pseudodist}
d(q_1,q_2):=\sqrt{(x_1-x_2)^2+(y_1+y_2)^2+C(I_1-I_2)},
\end{equation}
where $C$ is a conveniently chosen constant, so as to give a similar importance to the intensities as to the positions.
The integrated intensity of a CM is simply the denominator in the eq. \ref{cmparadisj}, that is, the total ``mass'' obtained by integrating the CSD in a specific disjoint component:
\begin{equation}
I_k(t)=\sum_j I (q_{j,k}, t)
\end{equation}
We specify then a tolerance $\delta$. If a certain $t$ a CM is below $\delta$ distance from another at $t+\Delta t$, we consider the latter the successor in time of the former. By continuously applying such procedure, we can begin to trace trajectories of the CMs, as they appear, wander, and fade. 

 
 \section{The Procedure}
\subsection{Recipe in a nutshell}
 
 In order to perform the analysis described here, we summarize the steps.
 \begin{enumerate}
 \item Acquire high density electro-physiological data. The data must be two or three dimensional in space. Distance between the recording sites must be of the order of the size of the typical neurons involved, and such sites must be on a dense enough grid to perform numerical difference operations over them. The sampling frequency should be enough to detect sub-threshold activity, of at least 5kHz. Also, the data should come from structured tissue. Unordered, highly homogeneous tissue, will not yield significant results. 
\item Obtain, frame by frame, the CSD from the data. Any method may be used, but computer expensive techniques are discouraged if the data is dense enough. Common sense and tests are guidelines here. We recommend simpler, difference based approaches. Our approach is detailed below.
\item Separate the CSD data into three sets: sources, sinks, and border or indiscernible (below error) data.
\item Perform disjoint component analysis in the sources and sinks sets, frame by frame.
  A single pass algorithm could be used here \cite{Vincent91, Abubaker07}.
\item  Obtain the CM for each disjoint component, using eq. \ref{cmparadisj}.
\item For each frame and its successor, and for each CM, perform a ``most probable successor'' detection. Here we must put numerical criteria according to the data avaible, i.e. how far away and how different in intensity should be allowed a CM to be at time $t+1$ to be considered succesor in time of another at time $t$. We use the distance defined in eq. \ref{pseudodist}, a sort of Euclidian-like distance. 
\item ``Connect the dots'', that is, apply succesively the step above for each CM, until it stops having a succesor or its intensity falls below the error criteria. Then plot the succesive CMs as one trayectory.
  \item Plot all the trayectories and sort visually those that may have physiological interpretation from those who may artifacts of the method. 
\end{enumerate}


\subsection{CSD for high density MEAS}

The concepts presented here require first obtaining the CSD from the recorded LFP. Any method would present the same utility. Thanks to the density and scales of the BioCAM 4096, in our case a ``classical'' numerical derivation of the CSD is the most adecuate route to take. A numerical Laplacian Operator which reduces the cross effect of rectangular grids is the convolution of the data with the following matrix \cite{Lindberg90}:
\begin{equation}
\nabla^2_{1/3}=(2/3)
\begin{pmatrix}
  0 & 1 & 0 \\
  1 & -4 & 1 \\
  0 & 1 & 0
\end{pmatrix}
+1/3
\begin{pmatrix}
  0.5 & 0 & 0.5 \\
  0 & -2 & 0 \\
  0.5 & 0 & 0.5
\end{pmatrix}  
\end{equation}
This sort of operators are extremely sensitive to edges. The noise of the data can be perceived in the spatial domain as rapidly varying edges. A Gaussian spatial denoising can be performed before or after the Laplacian operator to the data in order to reduce excessive borders. Our Gaussian blur filter has a $\sigma$ value of three electrodes or $126 \mu m$. Intuitively this means that it smooths over each structure smaller than the soma of a typical pyramidal cell. 
This is  in accordance to our mean field approach, where we expect smooth differentiable fields over the scale of the neurons, but not in finer scales (for details see \cite{Bedard11}, further work on this subject will be presented elsewhere \cite{IsabelYo}).

On previous works it has been argued that numerical difference operators sacrifice all data on the borders of the array. For electrode arrays of lesser density, this could posse a problem, but in our case we only renounce to 27 out of 4095 channels (one is grounded). More sophisticated methods such as iCSDA \cite{Leski2011} and kCSDA \cite{Potworowski2011} prove little advantage in estimating the sources under the ohmic, isotropic and homogeneous assumptions at the scales involved in our data, and turn out to be computer-costly for high density MEAs and dense temporal sampling.  

\section{Experimental examples}

The necessity to create such analysis came originally from the study of electro-physiological data obtained from the rat's hippocampus. The highly structured CA region of the hippocampus provides strong, discernible patterns of Sources and Sinks. Following the pattern of activity using Center of Mass analysis directly from the data, though, proves unfruitful, due to the non-convex nature of the layered tissue. Using CSD and disjoint component tracking over them provided the right conceptual framework to follow the displacement of active areas during highly active events, such as epileptic-like activity that was pharmacologically induced. The proposed analysis would not produce vector averages over different simultaneously active areas, on the contrary, it would separate them and track them independently. So the most violent epileptic burst provided us with the data necessary to prove the robustness of the method. 


\section{Application to epileptic-like activity in the hippocampus}
Chronologically speaking, we performed first the analysis to the most complicated data (numerically and qualitatively), which where a series of epileptic burst that occurred after 15 minutes of application of 4AP to living slices of hippocampus. The burst occurred with activity spreading over many sites simultaneously. This turned out to be a test of the applicability and robustness of our method. The necessity of having good error value for the ``thick zero'' set was more apparent here than anywhere else. Also the posibilty to create new structures of numerical data was seen here.  But also the most strickig features of the propagation of activity, coded now as trajectories of the CM, could be seen here, as the epileptic burst covered the whole CA structure. 

\section{Application to evoked activity in idem.}

The evoked activity seems to yield much cleaner results, as we can now compare the trajectories of successive, very similar events. Our CSD and CM analysis can be used to detect consistent features in these experiments, such as the direction the waxing and wanning of activity. Small deviations from the trajectory in successive experiments that are above the numerical error could indicate inconsistencies in the network below. 

\section{Application to spontaneous activity in idem.}

We had one experiment in which we could trace very nicely the data on DG and CA simultaneously without adding excitatory drugs. 

\bibliographystyle{abstract}
\bibliography{../Reportes/BiblioReportes01} 


\end{document}

